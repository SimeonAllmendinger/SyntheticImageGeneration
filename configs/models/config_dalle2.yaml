## Architecture

# CLIP
clip:
    #
    context_length: 77
    model_name: ViT-B-32            #ViT-H-14 | ViT-g-14 | ViT-bigG-14  # Best performing model on open_clip (DATE: 21.03.2023)
    pretrained: laion2B-s34B-b79K     #laion2B-s32B-b79K | laion2B-s12B-b42K | laion2b_s39b_b160k

# Diffusion Prior Network Parameters
diffusion_prior_network:
    params:
        dim: 512 # 1024 | 1280 
        depth: 6
        dim_head: 32 #64 | 80
        heads: 16 
        # Transformer: 80 x 16 = 1280 (=dim), which equals the embed dim of clip

# Diffusion Prior Parameters
diffusion_prior:

    use_existing_model: True

    params:
        image_embed_dim: 512 # 1024 | 1280
        timesteps: 1000
        sample_timesteps: 64
        cond_drop_prob: 0.2
        condition_on_text_encodings: False

# Diffusion Prior Trainer Parameters
diffusion_prior_trainer:

    model_save_path: ./src/assets/dalle2/models/DiffusionPriorTrainer_T45.pt
    train_with_embeds: True
    epochs: 10

    params:
        lr: 0.0003
        wd: 0.01
        ema_beta: 0.99
        ema_update_after_step: 1000
        ema_update_every: 10

# Decoder
decoder:

    use_existing_model: True

    params:
        image_sizes: # resolutions, 256 for first unet, 512 for second. these must be unique and in ascending order (matches with the unets passed in)
            - 128
            - 224    # 256 
        timesteps: 1000
        image_cond_drop_prob: 0.1
        text_cond_drop_prob: 0.5

# Decoder Trainer
decoder_trainer:

    model_save_path: ./src/assets/dalle2/models/DecoderTrainer_T45.pt
    train_with_embeds: False

    params:
        lr: 0.00003
        wd: 0.01  # weight decay
        ema_beta: 0.99
        ema_update_after_step: 1000
        ema_update_every: 10

# unet 1
unet1:
    dim: 32
    image_embed_dim: 512    # 1280
    text_embed_dim: 512     # 1280
    cond_dim: 128
    channels: 3
    cond_on_text_encodings: True # set to True for any unets that need to be conditioned on text encodings
    dim_mults:
        - 1
        - 2
        - 4
        - 8

unet2:
    dim: 16
    image_embed_dim: 512    # 1280
    cond_dim: 128
    channels: 3
    dim_mults:
        - 1
        - 2
        - 4
        - 8
        - 16
